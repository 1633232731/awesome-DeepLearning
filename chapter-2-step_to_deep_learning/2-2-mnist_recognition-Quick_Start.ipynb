{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "本节介绍使用飞桨快速实现“手写数字识别”的建模方法。\n",
    "\n",
    "与“房价预测”的案例类似，我们以同样的标准结构实现“手写数字识别”的建模。在后续的课程中，该标准结构会反复出现，逐渐加深我们对深度学习模型的理解。深度学习模型的标准结构分如下五个步骤：\n",
    "\n",
    "1. 数据处理：读取数据和预处理操作。\n",
    "2. 模型设计：搭建神经网络结构。\n",
    "3. 训练配置：配置优化器、学习率、训练参数。\n",
    "4. 训练过程：循环调用训练过程，循环执行“前向计算 + 损失函数 + 反向传播”。\n",
    "5. 保存模型并测试：将训练好的模型保存并评估测试。\n",
    "\n",
    "下面我们使用飞桨框架，按照五个步骤写“手写数字识别”模型，体会下使用飞桨框架的感觉。\n",
    "\n",
    "在数据处理前，首先要加载飞桨平台、与“手写数字识别”模型相关类库，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载飞桨和相关类库\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph.nn import Linear\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据处理\n",
    "\n",
    "飞桨提供了多个封装好的数据集API，覆盖计算机视觉、自然语言处理、推荐系统等多个领域，可以帮助我们快速完成机器学习任务。比如，在“手写数字识别”模型中，我们可以通过调用[paddle.dataset.mnist](https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/data/dataset_cn.html)的train函数和test函数，直接获取处理好的MNIST训练集和测试集。\n",
    "\n",
    "## 定义数据读取器\n",
    "\n",
    "用户可以通过如下代码定义数据读取器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /Users/liuweiwei06/.cache/paddle/dataset/mnist/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /Users/liuweiwei06/.cache/paddle/dataset/mnist/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "........\n",
      "Download finished\n"
     ]
    }
   ],
   "source": [
    "# 如果～/.cache/paddle/dataset/mnist/目录下没有MNIST数据，API会自动将MINST数据下载到该文件夹下\n",
    "# 设置数据读取器，读取MNIST数据训练集\n",
    "trainset = paddle.dataset.mnist.train()\n",
    "# 包装数据读取器，每次读取的数据数量设置为batch_size=8\n",
    "train_reader = paddle.batch(trainset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据，并打印观察\n",
    "\n",
    "paddle.batch函数将MNIST数据集拆分成多个批次，我们可以用下面的代码读取第一个批次的数据内容，并观察数据结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像数据形状和对应数据为: (8, 784) [-1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.9764706  -0.85882354 -0.85882354 -0.85882354\n",
      " -0.01176471  0.06666672  0.37254906 -0.79607844  0.30196083  1.\n",
      "  0.9372549  -0.00392157 -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.7647059  -0.7176471  -0.26274508  0.20784318\n",
      "  0.33333337  0.9843137   0.9843137   0.9843137   0.9843137   0.9843137\n",
      "  0.7647059   0.34901965  0.9843137   0.8980392   0.5294118  -0.4980392\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -0.6156863\n",
      "  0.8666667   0.9843137   0.9843137   0.9843137   0.9843137   0.9843137\n",
      "  0.9843137   0.9843137   0.9843137   0.96862745 -0.27058822 -0.35686272\n",
      " -0.35686272 -0.56078434 -0.69411767 -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -0.85882354  0.7176471   0.9843137\n",
      "  0.9843137   0.9843137   0.9843137   0.9843137   0.5529412   0.427451\n",
      "  0.9372549   0.8901961  -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.372549    0.22352946 -0.1607843   0.9843137\n",
      "  0.9843137   0.60784316 -0.9137255  -1.         -0.6627451   0.20784318\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -0.8901961  -0.99215686  0.20784318  0.9843137  -0.29411763\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.          0.09019613  0.9843137   0.4901961  -0.9843137  -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -0.9137255\n",
      "  0.4901961   0.9843137  -0.45098037 -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -0.7254902   0.8901961\n",
      "  0.7647059   0.254902   -0.15294117 -0.99215686 -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -0.36470586  0.88235295  0.9843137\n",
      "  0.9843137  -0.06666666 -0.8039216  -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.64705884  0.45882356  0.9843137   0.9843137\n",
      "  0.17647064 -0.7882353  -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -0.8745098  -0.27058822  0.9764706   0.9843137   0.4666667\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.          0.9529412   0.9843137   0.9529412  -0.4980392  -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.6392157   0.0196079   0.43529415  0.9843137\n",
      "  0.9843137   0.62352943 -0.9843137  -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -0.69411767  0.16078436\n",
      "  0.79607844  0.9843137   0.9843137   0.9843137   0.9607843   0.427451\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -0.8117647  -0.10588235  0.73333335  0.9843137   0.9843137   0.9843137\n",
      "  0.9843137   0.5764706  -0.38823527 -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -0.81960785 -0.4823529   0.67058825  0.9843137\n",
      "  0.9843137   0.9843137   0.9843137   0.5529412  -0.36470586 -0.9843137\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -0.85882354  0.3411765\n",
      "  0.7176471   0.9843137   0.9843137   0.9843137   0.9843137   0.5294118\n",
      " -0.372549   -0.92941177 -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -0.5686275   0.34901965  0.77254903  0.9843137   0.9843137   0.9843137\n",
      "  0.9843137   0.9137255   0.04313731 -0.9137255  -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.          0.06666672  0.9843137\n",
      "  0.9843137   0.9843137   0.6627451   0.05882359  0.03529418 -0.8745098\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.        ]\n",
      "图像标签形状和对应数据为: (8,) 5.0\n",
      "\n",
      "打印第一个batch的第一个图像，对应标签数字为5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 以迭代的形式读取数据\n",
    "for batch_id, data in enumerate(train_reader()):\n",
    "    # 获得图像数据，并转为float32类型的数组\n",
    "    img_data = np.array([x[0] for x in data]).astype('float32')\n",
    "    # 获得图像标签数据，并转为float32类型的数组\n",
    "    label_data = np.array([x[1] for x in data]).astype('float32')\n",
    "    # 打印数据形状\n",
    "    print(\"图像数据形状和对应数据为:\", img_data.shape, img_data[0])\n",
    "    print(\"图像标签形状和对应数据为:\", label_data.shape, label_data[0])\n",
    "    break\n",
    "\n",
    "print(\"\\n打印第一个batch的第一个图像，对应标签数字为{}\".format(label_data[0]))\n",
    "# 显示第一batch的第一个图像\n",
    "import matplotlib.pyplot as plt\n",
    "img = np.array(img_data[0]+1)*127.5\n",
    "img = np.reshape(img, [28, 28]).astype(np.uint8)\n",
    "\n",
    "plt.figure(\"Image\") # 图像窗口名称\n",
    "plt.imshow(img)\n",
    "plt.axis('on') # 关掉坐标轴为 off\n",
    "plt.title('image') # 图像题目\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从代码的输出来看，我们从数据加载器train_loader()中读取一次数据，可以得到形状为 (8, 784)的图像数据和形状为(8,)的标签数据。其中，8与设置的batch大小对应，784为mnist数据集中每个图像的像素数量(28*28)。\n",
    "\n",
    "另外，从打印的图像数据来看，图像数据的范围是[-1, 1]，表明这是已经完成图像归一化后的图像数据，且背景部分的值是-1。我们可以将图像数据反归一化，并使用matplotlib工具包将其显示出来。显示的数字是5，和对应标签数字一致。\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "飞桨将维度是28\\*28的手写数字数据图像转成向量形式存储，因此，使用飞桨数据读取到的手写数字图像是长度为784（28\\*28）的向量。\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 模型设计\n",
    "在“房价预测”深度学习任务中，我们使用了单层且没有非线性变换的模型，取得了理想的预测效果。在“手写数字识别”中，我们依然使用这个模型预测输入的图形数字值。其中，模型的输入为784维（28\\*28）数据，输出为1维数据，如**图1**所示。\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/80aea55a15ff4da1bb13a661f26cf8d97b19101e30e44c6fa5f5eb723ce5edb3\" width=\"300\" hegiht=\"200\"></center>\n",
    "\n",
    "<center><br>图1：与“房价预测”模型一样的简单网络</br></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义mnist数据识别网络结构，同房价预测网络\n",
    "class MNIST(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope):\n",
    "        super(MNIST, self).__init__(name_scope)\n",
    "        name_scope = self.full_name()\n",
    "        # 定义一层全连接层，输出维度是1，激活函数为None，即不使用激活函数\n",
    "        self.fc = Linear(input_dim=784, output_dim=1, act=None)\n",
    "        \n",
    "    # 定义网络结构的前向计算过程\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.fc(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 训练配置\n",
    "\n",
    "训练配置负责神经网络训练前的准备，包括：\n",
    "\n",
    "1. 声明定义好的模型。\n",
    "2. 加载训练数据和测试数据。\n",
    "3. 设置优化算法和学习率，本次实验优化算法使用随机梯度下降SGD，学习率使用 0.01。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义飞桨动态图工作环境\n",
    "with fluid.dygraph.guard():\n",
    "    # 声明网络结构\n",
    "    model = MNIST(\"mnist\")\n",
    "    # 启动训练模式\n",
    "    model.train()\n",
    "    # 定义数据读取函数，数据读取batch_size设置为16\n",
    "    train_loader = paddle.batch(paddle.dataset.mnist.train(), batch_size=16)\n",
    "    # 定义优化器，使用随机梯度下降SGD优化器，学习率设置为0.001\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.001, parameter_list=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 训练过程\n",
    "\n",
    "完成训练配置后，可启动训练过程。采用二层循环嵌套方式：\n",
    "- 内层循环负责整个数据集的一次遍历，遍历数据集采用分批次（batch）方式。\n",
    "- 外层循环定义遍历数据集的次数，本次训练中外层循环5次，通过参数EPOCH_NUM设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [12.650396]\n",
      "epoch: 0, batch: 1000, loss is: [1.8717564]\n",
      "epoch: 0, batch: 2000, loss is: [3.8958097]\n",
      "epoch: 0, batch: 3000, loss is: [3.553378]\n",
      "epoch: 1, batch: 0, loss is: [2.762073]\n",
      "epoch: 1, batch: 1000, loss is: [1.8074802]\n",
      "epoch: 1, batch: 2000, loss is: [3.9255028]\n",
      "epoch: 1, batch: 3000, loss is: [3.404625]\n",
      "epoch: 2, batch: 0, loss is: [2.5209904]\n",
      "epoch: 2, batch: 1000, loss is: [1.7918117]\n",
      "epoch: 2, batch: 2000, loss is: [3.8703609]\n",
      "epoch: 2, batch: 3000, loss is: [3.3211703]\n",
      "epoch: 3, batch: 0, loss is: [2.4786913]\n",
      "epoch: 3, batch: 1000, loss is: [1.7986146]\n",
      "epoch: 3, batch: 2000, loss is: [3.8277736]\n",
      "epoch: 3, batch: 3000, loss is: [3.2569842]\n",
      "epoch: 4, batch: 0, loss is: [2.4748836]\n",
      "epoch: 4, batch: 1000, loss is: [1.8120625]\n",
      "epoch: 4, batch: 2000, loss is: [3.8018284]\n",
      "epoch: 4, batch: 3000, loss is: [3.2037597]\n"
     ]
    }
   ],
   "source": [
    "# 通过with语句创建一个dygraph运行的context，\n",
    "# 动态图下的一些操作需要在guard下进行\n",
    "with fluid.dygraph.guard():\n",
    "    model = MNIST(\"mnist\")\n",
    "    model.train()\n",
    "    train_loader = paddle.batch(paddle.dataset.mnist.train(), batch_size=16)\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.001, parameter_list=model.parameters())\n",
    "    EPOCH_NUM = 5\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，格式需要转换成符合框架要求的\n",
    "            image_data = np.array([x[0] for x in data]).astype('float32')\n",
    "            label_data = np.array([x[1] for x in data]).astype('float32').reshape(-1, 1)\n",
    "            # 将数据转为飞桨动态图格式\n",
    "            image = fluid.dygraph.to_variable(image_data)\n",
    "            label = fluid.dygraph.to_variable(label_data)\n",
    "            \n",
    "            #前向计算的过程\n",
    "            predict = model(image)\n",
    "            \n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = fluid.layers.square_error_cost(predict, label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            \n",
    "            #每训练了1000批次的数据，打印下当前Loss的情况\n",
    "            if batch_id  % 1000 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            optimizer.minimize(avg_loss)\n",
    "            model.clear_gradients()\n",
    "\n",
    "    # 保存模型\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过观察训练过程中损失所发生的变化，可以发现虽然损失整体上在降低，但到训练的最后一轮，损失函数值依然较高。可以猜测，“手写数字识别”完全复用“房价预测”的代码，训练效果并不好。接下来我们通过模型测试，获取模型训练的真实效果。\n",
    "\n",
    "# 5. 模型测试\n",
    "\n",
    "\n",
    "模型测试的主要目的是验证训练好的模型是否能正确识别出数字。测试模型包括以下三步：\n",
    "\n",
    "- 从'./demo/example_0.jpg'目录下读取样例图片。\n",
    "- 加载模型并将模型的状态设置为校验状态（eval），显式告诉框架我们接下来只会使用前向计算的流程，不会计算梯度和梯度反向传播，这将减少内存的消耗。\n",
    "- 将测试样本传入模型，获取预测结果，取整后作为预测标签输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12f262a50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入图像读取第三方库\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "# 读取图像\n",
    "example = mpimg.imread('./work/example_0.jpg')\n",
    "# 显示图像\n",
    "plt.imshow(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "本次预测的数字是 [[3]]\n"
     ]
    }
   ],
   "source": [
    "# 读取一张本地的样例图片，转变成模型输入的格式\n",
    "def load_image(img_path):\n",
    "    # 从img_path中读取图像，并转为灰度图\n",
    "    im = Image.open(img_path).convert('L')\n",
    "    print(np.array(im))\n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)\n",
    "    im = np.array(im).reshape(1, -1).astype(np.float32)\n",
    "    # 图像归一化，保持和数据集的数据范围一致\n",
    "    im = 1 - im / 127.5\n",
    "    return im\n",
    "\n",
    "# 定义预测过程\n",
    "with fluid.dygraph.guard():\n",
    "    model = MNIST(\"mnist\")\n",
    "    params_file_path = 'mnist'\n",
    "    img_path = './work/example_0.png'\n",
    "    # 加载模型参数\n",
    "    model_dict, _ = fluid.load_dygraph(\"mnist\")\n",
    "    model.load_dict(model_dict)\n",
    "    # 灌入数据\n",
    "    model.eval()\n",
    "    tensor_img = load_image(img_path)\n",
    "    result = model(fluid.dygraph.to_variable(tensor_img))\n",
    "    #  预测输出取整，即为预测的数字，打印结果\n",
    "    print(\"本次预测的数字是\", result.numpy().astype('int32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从打印结果来看，模型预测出的数字是与实际输出的图片的数字不一致。这里只是验证了一个样本的情况，如果我们尝试更多的样本，可发现许多数字图片识别结果是错误的。因此完全复用房价预测的实验并不适用于手写数字识别任务！\n",
    "\n",
    "接下来我们会对手写数字识别实验模型进行逐一改进，直到获得令人满意的结果。\n",
    "\n",
    "\n",
    "\n",
    "## 思考题：\n",
    "\n",
    "1. 使用飞桨API [paddle.dataset.mnist](https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/data/dataset_cn.html)的test函数获得测试集数据，计算当前模型的准确率。\n",
    "\n",
    "2. 怎样进一步提高模型的准确率？对于手写数字识别任务，机械的套用“房价预测”的模型是不行的。接下来，我们将逐一考察模型的每个环节可以做出怎样的优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
