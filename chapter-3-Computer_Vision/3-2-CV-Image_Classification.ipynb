{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "图像分类是根据图像的语义信息对不同类别图像进行区分，是计算机视觉中重要的基础问题，是物体检测、图像分割、物体跟踪、行为分析、人脸识别等其他高层次视觉任务的基础。图像分类在许多领域都有着广泛的应用，如：安防领域的人脸识别和智能视频分析等，交通领域的交通场景识别，互联网领域基于内容的图像检索和相册自动归类，医学领域的图像识别等。\n",
    "\n",
    "上一节主要介绍了卷积神经网络常用的一些基本模块，本节将基于眼疾分类数据集iChallenge-PM，对图像分类领域的经典卷积神经网络进行剖析，介绍如何应用这些基础模块构建卷积神经网络，解决图像分类问题。涵盖如下卷积神经网络：\n",
    "\n",
    "- LeNet：Yan LeCun等人于1998年第一次将卷积神经网络应用到图像分类任务上[1]，在手写数字识别任务上取得了巨大成功。\n",
    "\n",
    "- AlexNet：Alex Krizhevsky等人在2012年提出了AlexNet[2], 并应用在大尺寸图片数据集ImageNet上，获得了2012年ImageNet比赛冠军(ImageNet Large Scale Visual Recognition Challenge，ILSVRC）。\n",
    "\n",
    "- VGG：Simonyan和Zisserman于2014年提出了VGG网络结构[3]，是当前最流行的卷积神经网络之一，由于其结构简单、应用性极强而深受广受研究者欢迎。\n",
    "\n",
    "- GoogLeNet：Christian Szegedy等人在2014提出了GoogLeNet[4]，并取得了2014年ImageNet比赛冠军。\n",
    "\n",
    "- ResNet：Kaiming He等人在2015年提出了ResNet[5]，通过引入残差模块加深网络层数，在ImagNet数据集上的识别错误率降低到3.6%，超越了人眼识别水平。ResNet的设计思想深刻的影响了后来的深度神经网络的设计。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LeNet\n",
    "\n",
    "LeNet是最早的卷积神经网络之一[1]。1998年，Yan LeCun第一次将LeNet卷积神经网络应用到图像分类上，在手写数字识别任务中取得了巨大成功。LeNet通过连续使用卷积和池化层的组合提取图像特征，其架构如 **图1** 所示，这里展示的是作者论文中的LeNet-5模型：\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/7323b32f61f24eba809db0b71fcd69eee7bd2921a81d42b4bd0e6f86c89efd51\" width = \"700\"></center>\n",
    "<center><br>图1：LeNet模型网络结构示意图</br></center>\n",
    "<br></br>\n",
    "\n",
    "* 第一轮卷积和池化：卷积提取图像中包含的特征模式（激活函数使用sigmoid），图像尺寸从32减小到28。经过池化层可以降低输出特征图对空间位置的敏感性，图像尺寸减到14。\n",
    "\n",
    "* 第二轮卷积和池化：卷积操作使图像尺寸减小到10，经过池化后变成5。\n",
    "\n",
    "* 第三轮卷积：将经过第3次卷积提取到的特征图输入到全连接层。第一个全连接层的输出神经元的个数是64，第二个全连接层的输出神经元个数是分类标签的类别数，对于手写数字识别其大小是10。然后使用Softmax激活函数即可计算出每个类别的预测概率。\n",
    "\n",
    "------\n",
    "**【提示】：**\n",
    "\n",
    "卷积层的输出特征图如何当作全连接层的输入使用呢？\n",
    "\n",
    "卷积层的输出数据格式是$[N, C, H, W]$，在输入全连接层的时候，会自动将数据拉平，\n",
    "\n",
    "也就是对每个样本，自动将其转化为长度为$K$的向量，\n",
    "\n",
    "其中$K = C \\times H \\times W$，一个mini-batch的数据维度变成了$N\\times K$的二维向量。\n",
    "\n",
    "------\n",
    "\n",
    "## LeNet在手写数字识别上的应用\n",
    "\n",
    "LeNet网络的实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入需要的包\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\n",
    "\n",
    "# 定义 LeNet 网络结构\n",
    "class LeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, num_classes=1):\n",
    "        super(LeNet, self).__init__(name_scope)\n",
    "\n",
    "        # 创建卷积和池化层块，每个卷积层使用Sigmoid激活函数，后面跟着一个2x2的池化\n",
    "        self.conv1 = Conv2D(num_channels=1, num_filters=6, filter_size=5, act='sigmoid')\n",
    "        self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv2 = Conv2D(num_channels=6, num_filters=16, filter_size=5, act='sigmoid')\n",
    "        self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        # 创建第3个卷积层\n",
    "        self.conv3 = Conv2D(num_channels=16, num_filters=120, filter_size=4, act='sigmoid')\n",
    "        # 创建全连接层，第一个全连接层的输出神经元个数为64， 第二个全连接层输出神经元个数为分裂标签的类别数\n",
    "        self.fc1 = Linear(input_dim=120, output_dim=64, act='sigmoid')\n",
    "        self.fc2 = Linear(input_dim=64, output_dim=num_classes)\n",
    "    # 网络的前向计算过程\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "下面的程序使用随机数作为输入，查看经过LeNet-5的每一层作用之后，输出数据的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<paddle.fluid.dygraph.nn.Conv2D object at 0x7ffb987c7c50>, <paddle.fluid.dygraph.nn.Pool2D object at 0x7ffb601a7950>, <paddle.fluid.dygraph.nn.Conv2D object at 0x7ffb601a7e30>, <paddle.fluid.dygraph.nn.Pool2D object at 0x7ffb601a7f50>, <paddle.fluid.dygraph.nn.Conv2D object at 0x7ffb601a7fb0>, <paddle.fluid.dygraph.nn.Linear object at 0x7ffb601c0110>, <paddle.fluid.dygraph.nn.Linear object at 0x7ffb601c0290>]\n",
      "conv2d_0 [3, 6, 24, 24] [6, 1, 5, 5] [6]\n",
      "pool2d_0 [3, 6, 12, 12]\n",
      "conv2d_1 [3, 16, 8, 8] [16, 6, 5, 5] [16]\n",
      "pool2d_1 [3, 16, 4, 4]\n",
      "conv2d_2 [3, 120, 1, 1] [120, 16, 4, 4] [120]\n",
      "linear_0 [3, 64] [120, 64] [64]\n",
      "linear_1 [3, 10] [64, 10] [10]\n"
     ]
    }
   ],
   "source": [
    "# 输入数据形状是 [N, 1, H, W]\n",
    "# 这里用np.random创建一个随机数组作为输入数据\n",
    "x = np.random.randn(*[3,1,28,28])\n",
    "x = x.astype('float32')\n",
    "with fluid.dygraph.guard():\n",
    "    # 创建LeNet类的实例，指定模型名称和分类的类别数目\n",
    "    m = LeNet('LeNet', num_classes=10)\n",
    "    # 通过调用LeNet从基类继承的sublayers()函数，\n",
    "    # 查看LeNet中所包含的子层\n",
    "    print(m.sublayers())\n",
    "    x = fluid.dygraph.to_variable(x)\n",
    "    for item in m.sublayers():\n",
    "        # item是LeNet类中的一个子层\n",
    "        # 查看经过子层之后的输出数据形状\n",
    "        try:\n",
    "            x = item(x)\n",
    "        except:\n",
    "            x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "            x = item(x)\n",
    "        if len(item.parameters())==2:\n",
    "            # 查看卷积和全连接层的数据和参数的形状，\n",
    "            # 其中item.parameters()[0]是权重参数w，item.parameters()[1]是偏置参数b\n",
    "            print(item.full_name(), x.shape, item.parameters()[0].shape, item.parameters()[1].shape)\n",
    "        else:\n",
    "            # 池化层没有参数\n",
    "            print(item.full_name(), x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \n",
      "epoch: 0, batch_id: 0, loss is: [2.6988614]\n",
      "epoch: 0, batch_id: 1000, loss is: [2.2943656]\n",
      "epoch: 0, batch_id: 2000, loss is: [2.335095]\n",
      "epoch: 0, batch_id: 3000, loss is: [2.2748592]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# LeNet 识别手写数字\n",
    "\n",
    "import os\n",
    "import random\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "\n",
    "# 定义训练过程\n",
    "def train(model):\n",
    "    print('start training ... ')\n",
    "    model.train()\n",
    "    epoch_num = 5\n",
    "    opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameter_list=model.parameters())\n",
    "    # 使用Paddle自带的数据读取器\n",
    "    train_loader = paddle.batch(paddle.dataset.mnist.train(), batch_size=10)\n",
    "    valid_loader = paddle.batch(paddle.dataset.mnist.test(), batch_size=10)\n",
    "    for epoch in range(epoch_num):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            # 调整输入数据形状和类型\n",
    "            x_data = np.array([item[0] for item in data], dtype='float32').reshape(-1, 1, 28, 28)\n",
    "            y_data = np.array([item[1] for item in data], dtype='int64').reshape(-1, 1)\n",
    "            # 将numpy.ndarray转化成Tensor\n",
    "            img = fluid.dygraph.to_variable(x_data)\n",
    "            label = fluid.dygraph.to_variable(y_data)\n",
    "            # 计算模型输出\n",
    "            logits = model(img)\n",
    "            # 计算损失函数\n",
    "            loss = fluid.layers.softmax_with_cross_entropy(logits, label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            if batch_id % 1000 == 0:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "            avg_loss.backward()\n",
    "            opt.minimize(avg_loss)\n",
    "            model.clear_gradients()\n",
    "\n",
    "        model.eval()\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        for batch_id, data in enumerate(valid_loader()):\n",
    "            # 调整输入数据形状和类型\n",
    "            x_data = np.array([item[0] for item in data], dtype='float32').reshape(-1, 1, 28, 28)\n",
    "            y_data = np.array([item[1] for item in data], dtype='int64').reshape(-1, 1)\n",
    "            # 将numpy.ndarray转化成Tensor\n",
    "            img = fluid.dygraph.to_variable(x_data)\n",
    "            label = fluid.dygraph.to_variable(y_data)\n",
    "            # 计算模型输出\n",
    "            logits = model(img)\n",
    "            pred = fluid.layers.softmax(logits)\n",
    "            # 计算损失函数\n",
    "            loss = fluid.layers.softmax_with_cross_entropy(logits, label)\n",
    "            acc = fluid.layers.accuracy(pred, label)\n",
    "            accuracies.append(acc.numpy())\n",
    "            losses.append(loss.numpy())\n",
    "        print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "        model.train()\n",
    "\n",
    "    # 保存模型参数\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建模型\n",
    "    with fluid.dygraph.guard():\n",
    "        model = LeNet(\"LeNet\", num_classes=10)\n",
    "        #启动训练过程\n",
    "        train(model)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "通过运行结果可以看出，LeNet在手写数字识别MNIST验证数据集上的准确率高达92%以上。那么对于其它数据集效果如何呢？我们通过眼疾识别数据集iChallenge-PM验证一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## LeNet在眼疾识别数据集iChallenge-PM上的应用\n",
    "\n",
    "[iChallenge-PM](https://ai.baidu.com/broad/introduction)是百度大脑和中山大学中山眼科中心联合举办的iChallenge比赛中，提供的关于病理性近视（Pathologic Myopia，PM）的医疗类数据集，包含1200个受试者的眼底视网膜图片，训练、验证和测试数据集各400张。下面我们详细介绍LeNet在iChallenge-PM上的训练过程。\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "如今近视已经成为困扰人们健康的一项全球性负担，在近视人群中，有超过35%的人患有重度近视。近似将会导致眼睛的光轴被拉长，有可能引起视网膜或者络网膜的病变。随着近似度数的不断加深，高度近似有可能引发病理性病变，这将会导致以下几种症状：视网膜或者络网膜发生退化、视盘区域萎缩、漆裂样纹损害、Fuchs斑等。因此，及早发现近似患者眼睛的病变并采取治疗，显得非常重要。\n",
    "\n",
    "数据可以从AIStudio[下载](https://aistudio.baidu.com/aistudio/datasetdetail/19065)\n",
    "\n",
    "------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 数据集准备\n",
    "\n",
    "/home/aistudio/data/data19065 目录包括如下三个文件，解压缩后存放在/home/aistudio/work/palm目录下。\n",
    "- training.zip：包含训练中的图片和标签\n",
    "- validation.zip：包含验证集的图片\n",
    "- valid_gt.zip：包含验证集的标签\n",
    "\n",
    "------\n",
    "**注意**：\n",
    "\n",
    "valid_gt.zip文件解压缩之后，需要将/home/aistudio/work/palm/PALM-Validation-GT/目录下的PM_Label_and_Fovea_Location.xlsx文件转存成csv格式，本节代码示例中已经提前转成文件labels.csv。\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 初次运行时将注释取消，以便解压文件\n",
    "# 如果已经解压过了，则不需要运行此段代码，否则文件已经存在解压会报错\n",
    "#!unzip -d /home/aistudio/work/palm /home/aistudio/data/data19065/training.zip\n",
    "#%cd /home/aistudio/work/palm/PALM-Training400/\n",
    "#!unzip PALM-Training400.zip\n",
    "#!unzip -d /home/aistudio/work/palm /home/aistudio/data/data19065/validation.zip\n",
    "#!unzip -d /home/aistudio/work/palm /home/aistudio/data/data19065/valid_gt.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 查看数据集图片\n",
    "\n",
    "iChallenge-PM中既有病理性近视患者的眼底图片，也有非病理性近视患者的图片，命名规则如下：\n",
    "\n",
    "- 病理性近视（PM）：文件名以P开头\n",
    "\n",
    "- 非病理性近视（non-PM）：\n",
    "\n",
    "  * 高度近似（high myopia）：文件名以H开头\n",
    "  \n",
    "  * 正常眼睛（normal）：文件名以N开头\n",
    "\n",
    "我们将病理性患者的图片作为正样本，标签为1； 非病理性患者的图片作为负样本，标签为0。从数据集中选取两张图片，通过LeNet提取特征，构建分类器，对正负样本进行分类，并将图片显示出来。代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "\n",
    "DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'\n",
    "# 文件名以N开头的是正常眼底图片，以P开头的是病变眼底图片\n",
    "file1 = 'N0012.jpg'\n",
    "file2 = 'P0095.jpg'\n",
    "\n",
    "# 读取图片\n",
    "img1 = Image.open(os.path.join(DATADIR, file1))\n",
    "img1 = np.array(img1)\n",
    "img2 = Image.open(os.path.join(DATADIR, file2))\n",
    "img2 = np.array(img2)\n",
    "\n",
    "# 画出读取的图片\n",
    "plt.figure(figsize=(16, 8))\n",
    "f = plt.subplot(121)\n",
    "f.set_title('Normal', fontsize=20)\n",
    "plt.imshow(img1)\n",
    "f = plt.subplot(122)\n",
    "f.set_title('PM', fontsize=20)\n",
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看图片形状\n",
    "img1.shape, img2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 定义数据读取器\n",
    "\n",
    "使用OpenCV从磁盘读入图片，将每张图缩放到$224\\times224$大小，并且将像素值调整到$[-1, 1]$之间，代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# 对读入的图像数据进行预处理\n",
    "def transform_img(img):\n",
    "    # 将图片尺寸缩放道 224x224\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    # 读入的图像数据格式是[H, W, C]\n",
    "    # 使用转置操作将其变成[C, H, W]\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    img = img.astype('float32')\n",
    "    # 将数据范围调整到[-1.0, 1.0]之间\n",
    "    img = img / 255.\n",
    "    img = img * 2.0 - 1.0\n",
    "    return img\n",
    "\n",
    "# 定义训练集数据读取器\n",
    "def data_loader(datadir, batch_size=10, mode = 'train'):\n",
    "    # 将datadir目录下的文件列出来，每条文件都要读入\n",
    "    filenames = os.listdir(datadir)\n",
    "    def reader():\n",
    "        if mode == 'train':\n",
    "            # 训练时随机打乱数据顺序\n",
    "            random.shuffle(filenames)\n",
    "        batch_imgs = []\n",
    "        batch_labels = []\n",
    "        for name in filenames:\n",
    "            filepath = os.path.join(datadir, name)\n",
    "            img = cv2.imread(filepath)\n",
    "            img = transform_img(img)\n",
    "            if name[0] == 'H' or name[0] == 'N':\n",
    "                # H开头的文件名表示高度近似，N开头的文件名表示正常视力\n",
    "                # 高度近视和正常视力的样本，都不是病理性的，属于负样本，标签为0\n",
    "                label = 0\n",
    "            elif name[0] == 'P':\n",
    "                # P开头的是病理性近视，属于正样本，标签为1\n",
    "                label = 1\n",
    "            else:\n",
    "                raise('Not excepted file name')\n",
    "            # 每读取一个样本的数据，就将其放入数据列表中\n",
    "            batch_imgs.append(img)\n",
    "            batch_labels.append(label)\n",
    "            if len(batch_imgs) == batch_size:\n",
    "                # 当数据列表的长度等于batch_size的时候，\n",
    "                # 把这些数据当作一个mini-batch，并作为数据生成器的一个输出\n",
    "                imgs_array = np.array(batch_imgs).astype('float32')\n",
    "                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "                yield imgs_array, labels_array\n",
    "                batch_imgs = []\n",
    "                batch_labels = []\n",
    "\n",
    "        if len(batch_imgs) > 0:\n",
    "            # 剩余样本数目不足一个batch_size的数据，一起打包成一个mini-batch\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "            yield imgs_array, labels_array\n",
    "\n",
    "    return reader\n",
    "\n",
    "# 定义验证集数据读取器\n",
    "def valid_data_loader(datadir, csvfile, batch_size=10, mode='valid'):\n",
    "    # 训练集读取时通过文件名来确定样本标签，验证集则通过csvfile来读取每个图片对应的标签\n",
    "    # 请查看解压后的验证集标签数据，观察csvfile文件里面所包含的内容\n",
    "    # csvfile文件所包含的内容格式如下，每一行代表一个样本，\n",
    "    # 其中第一列是图片id，第二列是文件名，第三列是图片标签，\n",
    "    # 第四列和第五列是Fovea的坐标，与分类任务无关\n",
    "    # ID,imgName,Label,Fovea_X,Fovea_Y\n",
    "    # 1,V0001.jpg,0,1157.74,1019.87\n",
    "    # 2,V0002.jpg,1,1285.82,1080.47\n",
    "    # 打开包含验证集标签的csvfile，并读入其中的内容\n",
    "    filelists = open(csvfile).readlines()\n",
    "    def reader():\n",
    "        batch_imgs = []\n",
    "        batch_labels = []\n",
    "        for line in filelists[1:]:\n",
    "            line = line.strip().split(',')\n",
    "            name = line[1]\n",
    "            label = int(line[2])\n",
    "            # 根据图片文件名加载图片，并对图像数据作预处理\n",
    "            filepath = os.path.join(datadir, name)\n",
    "            img = cv2.imread(filepath)\n",
    "            img = transform_img(img)\n",
    "            # 每读取一个样本的数据，就将其放入数据列表中\n",
    "            batch_imgs.append(img)\n",
    "            batch_labels.append(label)\n",
    "            if len(batch_imgs) == batch_size:\n",
    "                # 当数据列表的长度等于batch_size的时候，\n",
    "                # 把这些数据当作一个mini-batch，并作为数据生成器的一个输出\n",
    "                imgs_array = np.array(batch_imgs).astype('float32')\n",
    "                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "                yield imgs_array, labels_array\n",
    "                batch_imgs = []\n",
    "                batch_labels = []\n",
    "\n",
    "        if len(batch_imgs) > 0:\n",
    "            # 剩余样本数目不足一个batch_size的数据，一起打包成一个mini-batch\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "            yield imgs_array, labels_array\n",
    "\n",
    "    return reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看数据形状\n",
    "DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'\n",
    "train_loader = data_loader(DATADIR, \n",
    "                           batch_size=10, mode='train')\n",
    "data_reader = train_loader()\n",
    "data = next(data_reader)\n",
    "data[0].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# LeNet 识别眼疾图片\n",
    "\n",
    "import os\n",
    "import random\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "\n",
    "DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'\n",
    "DATADIR2 = '/home/aistudio/work/palm/PALM-Validation400'\n",
    "CSVFILE = '/home/aistudio/work/palm/PALM-Validation-GT/labels.csv'\n",
    "\n",
    "# 定义训练过程\n",
    "def train(model):\n",
    "    with fluid.dygraph.guard():\n",
    "        print('start training ... ')\n",
    "        model.train()\n",
    "        epoch_num = 5\n",
    "        # 定义优化器\n",
    "        opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameter_list=model.parameters())\n",
    "        # 定义数据读取器，训练数据读取器和验证数据读取器\n",
    "        train_loader = data_loader(DATADIR, batch_size=10, mode='train')\n",
    "        valid_loader = valid_data_loader(DATADIR2, CSVFILE)\n",
    "        for epoch in range(epoch_num):\n",
    "            for batch_id, data in enumerate(train_loader()):\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits = model(img)\n",
    "                # 进行loss计算\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "\n",
    "                if batch_id % 10 == 0:\n",
    "                    print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "                # 反向传播，更新权重，清除梯度\n",
    "                avg_loss.backward()\n",
    "                opt.minimize(avg_loss)\n",
    "                model.clear_gradients()\n",
    "\n",
    "            model.eval()\n",
    "            accuracies = []\n",
    "            losses = []\n",
    "            for batch_id, data in enumerate(valid_loader()):\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits = model(img)\n",
    "                # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "                # 计算sigmoid后的预测概率，进行loss计算\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                # 计算预测概率小于0.5的类别\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                # 得到两个类别的预测概率，并沿第一个维度级联\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                accuracies.append(acc.numpy())\n",
    "                losses.append(loss.numpy())\n",
    "            print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "            model.train()\n",
    "\n",
    "        # save params of model\n",
    "        fluid.save_dygraph(model.state_dict(), 'mnist')\n",
    "        # save optimizer state\n",
    "        fluid.save_dygraph(opt.state_dict(), 'mnist')\n",
    "\n",
    "\n",
    "# 定义评估过程\n",
    "def evaluation(model, params_file_path):\n",
    "    with fluid.dygraph.guard():\n",
    "        print('start evaluation .......')\n",
    "        #加载模型参数\n",
    "        model_state_dict, _ = fluid.load_dygraph(params_file_path)\n",
    "        model.load_dict(model_state_dict)\n",
    "\n",
    "        model.eval()\n",
    "        eval_loader = load_data('eval')\n",
    "\n",
    "        acc_set = []\n",
    "        avg_loss_set = []\n",
    "        for batch_id, data in enumerate(eval_loader()):\n",
    "            x_data, y_data = data\n",
    "            img = fluid.dygraph.to_variable(x_data)\n",
    "            label = fluid.dygraph.to_variable(y_data)\n",
    "            # 计算预测和精度\n",
    "            prediction, acc = model(img, label)\n",
    "            # 计算损失函数值\n",
    "            loss = fluid.layers.cross_entropy(input=prediction, label=label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            acc_set.append(float(acc.numpy()))\n",
    "            avg_loss_set.append(float(avg_loss.numpy()))\n",
    "        # 求平均精度\n",
    "        acc_val_mean = np.array(acc_set).mean()\n",
    "        avg_loss_val_mean = np.array(avg_loss_set).mean()\n",
    "\n",
    "        print('loss={}, acc={}'.format(avg_loss_val_mean, acc_val_mean))\n",
    "\n",
    "# 导入需要的包\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\n",
    "\n",
    "# 定义 LeNet 网络结构\n",
    "class LeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, num_classes=1):\n",
    "        super(LeNet, self).__init__(name_scope)\n",
    "\n",
    "        # 创建卷积和池化层块，每个卷积层使用Sigmoid激活函数，后面跟着一个2x2的池化\n",
    "        self.conv1 = Conv2D(num_channels=3, num_filters=6, filter_size=5, act='sigmoid')\n",
    "        self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv2 = Conv2D(num_channels=6, num_filters=16, filter_size=5, act='sigmoid')\n",
    "        self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        # 创建第3个卷积层\n",
    "        self.conv3 = Conv2D(num_channels=16, num_filters=120, filter_size=4, act='sigmoid')\n",
    "        # 创建全连接层，第一个全连接层的输出神经元个数为64， 第二个全连接层输出神经元个数为分裂标签的类别数\n",
    "        self.fc1 = Linear(input_dim=300000, output_dim=64, act='sigmoid')\n",
    "        self.fc2 = Linear(input_dim=64, output_dim=num_classes)\n",
    "    # 网络的前向计算过程\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建模型\n",
    "    with fluid.dygraph.guard():\n",
    "        model = LeNet(\"LeNet_\", num_classes=1)\n",
    "\n",
    "    train(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "通过运行结果可以看出，在眼疾筛查数据集iChallenge-PM上，LeNet的loss很难下降，模型没有收敛。这是因为MNIST数据集的图片尺寸比较小（$28\\times28$），但是眼疾筛查数据集图片尺寸比较大（原始图片尺寸约为$2000 \\times 2000$，经过缩放之后变成$224 \\times 224$），LeNet模型很难进行有效分类。这说明在图片尺寸比较大时，LeNet在图像分类任务上存在局限性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## AlexNet\n",
    "\n",
    "\n",
    "通过上面的实际训练可以看到，虽然LeNet在手写数字识别数据集上取得了很好的结果，但在更大的数据集上表现却并不好。自从1998年LeNet问世以来，接下来十几年的时间里，神经网络并没有在计算机视觉领域取得很好的结果，反而一度被其它算法所超越，原因主要有两方面，一是神经网络的计算比较复杂，对当时计算机的算力来说，训练神经网络是件非常耗时的事情；另一方面，当时还没有专门针对神经网络做算法和训练技巧的优化，神经网络的收敛性是件非常困难的事情。\n",
    "\n",
    "随着技术的进步和发展，计算机的算力越来越强大，尤其是在GPU并行计算能力的推动下，复杂神经网络的计算也变得更加容易实施。另一方面，互联网上涌现出越来越多的数据，极大的丰富了数据库。同时也有越来越多的研究人员开始专门针对神经网络做算法和模型的优化，Alex Krizhevsky等人提出的AlexNet以很大优势获得了2012年ImageNet比赛的冠军。这一成果极大的激发了业界对神经网络的兴趣，开创了使用深度神经网络解决图像问题的途径，随后也在这一领域涌现出越来越多的优秀工作。\n",
    "\n",
    "AlexNet与LeNet相比，具有更深的网络结构，包含5层卷积和3层全连接，同时使用了如下三种方法改进模型的训练过程：\n",
    "\n",
    "  - 数据增多：深度学习中常用的一种处理方式，通过对训练随机加一些变化，比如平移、缩放、裁剪、旋转、翻转或者增减亮度等，产生一系列跟原始图片相似但又不完全相同的样本，从而扩大训练数据集。通过这种方式，可以随机改变训练样本，避免模型过度依赖于某些属性，能从一定程度上抑制过拟合。\n",
    "  \n",
    "  - 使用Dropout抑制过拟合\n",
    "  \n",
    "  - 使用ReLU激活函数少梯度消失现象\n",
    "  \n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "下一节详细介绍数据增多的具体实现方式。\n",
    "\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "AlexNet的具体结构如 **图2** 所示：\n",
    "\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/d28eb5b9ad2c458a9922e528312486eb994529fdfabd4a9488c33746a3e1dac7\" width = \"700\"></center>\n",
    "<center><br>图2：AlexNet模型网络结构示意图</br></center>\n",
    "<br></br>\n",
    "\n",
    "AlexNet在眼疾筛查数据集iChallenge-PM上具体实现的代码如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# 导入需要的包\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\n",
    "\n",
    "\n",
    "# 定义 AlexNet 网络结构\n",
    "class AlexNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, num_classes=1):\n",
    "        super(AlexNet, self).__init__(name_scope)\n",
    "        name_scope = self.full_name()\n",
    "        # AlexNet与LeNet一样也会同时使用卷积和池化层提取图像特征\n",
    "        # 与LeNet不同的是激活函数换成了‘relu’\n",
    "        self.conv1 = Conv2D(num_channels=3, num_filters=96, filter_size=11, stride=4, padding=5, act='relu')\n",
    "        self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv2 = Conv2D(num_channels=96, num_filters=256, filter_size=5, stride=1, padding=2, act='relu')\n",
    "        self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv3 = Conv2D(num_channels=256, num_filters=384, filter_size=3, stride=1, padding=1, act='relu')\n",
    "        self.conv4 = Conv2D(num_channels=384, num_filters=384, filter_size=3, stride=1, padding=1, act='relu')\n",
    "        self.conv5 = Conv2D(num_channels=384, num_filters=256, filter_size=3, stride=1, padding=1, act='relu')\n",
    "        self.pool5 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "\n",
    "        self.fc1 = Linear(input_dim=12544, output_dim=4096, act='relu')\n",
    "        self.drop_ratio1 = 0.5\n",
    "        self.fc2 = Linear(input_dim=4096, output_dim=4096, act='relu')\n",
    "        self.drop_ratio2 = 0.5\n",
    "        self.fc3 = Linear(input_dim=4096, output_dim=num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.pool5(x)\n",
    "        x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        # 在全连接之后使用dropout抑制过拟合\n",
    "        x= fluid.layers.dropout(x, self.drop_ratio1)\n",
    "        x = self.fc2(x)\n",
    "        # 在全连接之后使用dropout抑制过拟合\n",
    "        x = fluid.layers.dropout(x, self.drop_ratio2)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    model = AlexNet(\"AlexNet\")\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "通过运行结果可以发现，在眼疾筛查数据集iChallenge-PM上使用AlexNet，loss能有效下降，经过5个epoch的训练，在验证集上的准确率可以达到94%左右。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## VGG\n",
    "\n",
    "VGG是当前最流行的CNN模型之一，2014年由Simonyan和Zisserman提出，其命名来源于论文作者所在的实验室Visual Geometry Group。AlexNet模型通过构造多层网络，取得了较好的效果，但是并没有给出深度神经网络设计的方向。VGG通过使用一系列大小为3x3的小尺寸卷积核和pooling层构造深度卷积神经网络，并取得了较好的效果。VGG模型因为结构简单、应用性极强而广受研究者欢迎，尤其是它的网络结构设计方法，为构建深度神经网络提供了方向。\n",
    "\n",
    "**图3** 是VGG-16的网络结构示意图，有13层卷积和3层全连接层。VGG网络的设计严格使用$3\\times 3$的卷积层和池化层来提取特征，并在网络的最后面使用三层全连接层，将最后一层全连接层的输出作为分类的预测。\n",
    "在VGG中每层卷积将使用ReLU作为激活函数，在全连接层之后添加dropout来抑制过拟合。使用小的卷积核能够有效地减少参数的个数，使得训练和测试变得更加有效。比如使用两层$3\\times 3$卷积层，可以得到感受野为5的特征图，而比使用$5 \\times 5$的卷积层需要更少的参数。由于卷积核比较小，可以堆叠更多的卷积层，加深网络的深度，这对于图像分类任务来说是有利的。VGG模型的成功证明了增加网络的深度，可以更好的学习图像中的特征模式。\n",
    "\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/f22dc04130f24933865fbd82e61fb8e2e15849dc4a2e411ea785dea239de6cfe\" width = \"700\"></center>\n",
    "<center><br>图3：VGG模型网络结构示意图</br></center>\n",
    "<br></br>\n",
    "\n",
    "VGG在眼疾识别数据集iChallenge-PM上的具体实现如下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# VGG模型代码\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.layer_helper import LayerHelper\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, Linear\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "\n",
    "# 定义vgg块，包含多层卷积和1层2x2的最大池化层\n",
    "class vgg_block(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, num_convs, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        num_convs, 卷积层的数目\n",
    "        num_channels, 卷积层的输出通道数，在同一个Incepition块内，卷积层输出通道数是一样的\n",
    "        \"\"\"\n",
    "        super(vgg_block, self).__init__(name_scope)\n",
    "        self.conv_list = []\n",
    "        for i in range(num_convs):\n",
    "            conv_layer = self.add_sublayer('conv_' + str(i), Conv2D(num_channels=in_channels, \n",
    "                                        num_filters=out_channels, filter_size=3, padding=1, act='relu'))\n",
    "            self.conv_list.append(conv_layer)\n",
    "            in_channels = out_channels\n",
    "        self.pool = Pool2D(pool_stride=2, pool_size = 2, pool_type='max')\n",
    "    def forward(self, x):\n",
    "        for item in self.conv_list:\n",
    "            x = item(x)\n",
    "        return self.pool(x)\n",
    "\n",
    "class VGG(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, conv_arch=((2, 64), \n",
    "                                (2, 128), (3, 256), (3, 512), (3, 512))):\n",
    "        super(VGG, self).__init__(name_scope)\n",
    "        self.vgg_blocks=[]\n",
    "        iter_id = 0\n",
    "        # 添加vgg_block\n",
    "        # 这里一共5个vgg_block，每个block里面的卷积层数目和输出通道数由conv_arch指定\n",
    "        in_channels = [3, 64, 128, 256, 512, 512]\n",
    "        for (num_convs, num_channels) in conv_arch:\n",
    "            block = self.add_sublayer('block_' + str(iter_id), \n",
    "                    vgg_block(self.full_name(), num_convs, in_channels=in_channels[iter_id], \n",
    "                              out_channels=num_channels))\n",
    "            self.vgg_blocks.append(block)\n",
    "            iter_id += 1\n",
    "        self.fc1 = Linear(input_dim=512*7*7, output_dim=4096,\n",
    "                      act='relu')\n",
    "        self.drop1_ratio = 0.5\n",
    "        self.fc2= Linear(input_dim=4096, output_dim=4096,\n",
    "                      act='relu')\n",
    "        self.drop2_ratio = 0.5\n",
    "        self.fc3 = Linear(input_dim=4096, output_dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for item in self.vgg_blocks:\n",
    "            x = item(x)\n",
    "        x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x = fluid.layers.dropout(self.fc1(x), self.drop1_ratio)\n",
    "        x = fluid.layers.dropout(self.fc2(x), self.drop2_ratio)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    model = VGG(\"VGG\")\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "通过运行结果可以发现，在眼疾筛查数据集iChallenge-PM上使用VGG，loss能有效的下降，经过5个epoch的训练，在验证集上的准确率可以达到94%左右。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## GoogLeNet\n",
    "\n",
    "GoogLeNet是2014年ImageNet比赛的冠军，它的主要特点是网络不仅有深度，还在横向上具有“宽度”。由于图像信息在空间尺寸上的巨大差异，如何选择合适的卷积核大小来提取特征就显得比较困难了。空间分布范围更广的图像信息适合用较大的卷积核来提取其特征，而空间分布范围较小的图像信息则适合用较小的卷积核来提取其特征。为了解决这个问题，GoogLeNet提出了一种被称为Inception模块的方案。如 **图4** 所示：\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "- Google的研究人员为了向LeNet致敬，特地将模型命名为GoogLeNet\n",
    "- Inception一词来源于电影《盗梦空间》（Inception）\n",
    "------\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/96f92806a70446e880d87bad5f7b7d8936c36abcb1ff4fcd9c3391ae5fca902d\" width = \"700\"></center>\n",
    "<center><br>图4：Inception模块结构示意图</br></center>\n",
    "<br></br>\n",
    "图4(a)是Inception模块的设计思想，使用3个不同大小的卷积核对输入图片进行卷积操作，并附加最大池化，将这4个操作的输出沿着通道这一维度进行拼接，构成的输出特征图将会包含经过不同大小的卷积核提取出来的特征。Inception模块采用多通路(multi-path)的设计形式，每个支路使用不同大小的卷积核，最终输出特征图的通道数是每个支路输出通道数的总和，这将会导致输出通道数变得很大，尤其是使用多个Inception模块串联操作的时候，模型参数量会变得非常巨大。为了减小参数量，Inception模块使用了图(b)中的设计方式，在每个3x3和5x5的卷积层之前，增加1x1的卷积层来控制输出通道数；在最大池化层后面增加1x1卷积层减小输出通道数。基于这一设计思想，形成了上图(b)中所示的结构。下面这段程序是Inception块的具体实现方式，可以对照图(b)和代码一起阅读。\n",
    "\n",
    "------\n",
    "**提示：**\n",
    "\n",
    "可能有读者会问，经过3x3的最大池化之后图像尺寸不会减小吗，为什么还能跟另外3个卷积输出的特征图进行拼接？这是因为池化操作可以指定窗口大小$k_h = K_w = 3$，pool_stride=1和pool_padding=1，输出特征图尺寸可以保持不变。\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Inception模块的具体实现如下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Inception(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, c1, c2, c3, c4, **kwargs):\n",
    "        '''\n",
    "        Inception模块的实现代码，\n",
    "        name_scope, 模块名称，数据类型为string\n",
    "        c1,  图(b)中第一条支路1x1卷积的输出通道数，数据类型是整数\n",
    "        c2，图(b)中第二条支路卷积的输出通道数，数据类型是tuple或list, \n",
    "               其中c2[0]是1x1卷积的输出通道数，c2[1]是3x3\n",
    "        c3，图(b)中第三条支路卷积的输出通道数，数据类型是tuple或list, \n",
    "               其中c3[0]是1x1卷积的输出通道数，c3[1]是3x3\n",
    "        c4,  图(b)中第一条支路1x1卷积的输出通道数，数据类型是整数\n",
    "        '''\n",
    "        super(Inception, self).__init__(name_scope)\n",
    "        # 依次创建Inception块每条支路上使用到的操作\n",
    "        self.p1_1 = Conv2D(self.full_name(), num_filters=c1, \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p2_1 = Conv2D(self.full_name(), num_filters=c2[0], \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p2_2 = Conv2D(self.full_name(), num_filters=c2[1], \n",
    "                           filter_size=3, padding=1, act='relu')\n",
    "        self.p3_1 = Conv2D(self.full_name(), num_filters=c3[0], \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p3_2 = Conv2D(self.full_name(), num_filters=c3[1], \n",
    "                           filter_size=5, padding=2, act='relu')\n",
    "        self.p4_1 = Pool2D(self.full_name(), pool_size=3, \n",
    "                           pool_stride=1,  pool_padding=1, \n",
    "                           pool_type='max')\n",
    "        self.p4_2 = Conv2D(self.full_name(), num_filters=c4, \n",
    "                           filter_size=1, act='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 支路1只包含一个1x1卷积\n",
    "        p1 = self.p1_1(x)\n",
    "        # 支路2包含 1x1卷积 + 3x3卷积\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        # 支路3包含 1x1卷积 + 5x5卷积\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        # 支路4包含 最大池化和1x1卷积\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # 将每个支路的输出特征图拼接在一起作为最终的输出结果\n",
    "        return fluid.layers.concat([p1, p2, p3, p4], axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "GoogLeNet的架构如 **图5** 所示，在主体卷积部分中使用5个模块（block），每个模块之间使用步幅为2的3 ×3最大池化层来减小输出高宽。\n",
    "* 第一模块使用一个64通道的7 × 7卷积层。\n",
    "* 第二模块使用2个卷积层:首先是64通道的1 × 1卷积层，然后是将通道增大3倍的3 × 3卷积层。\n",
    "* 第三模块串联2个完整的Inception块。\n",
    "* 第四模块串联了5个Inception块。\n",
    "* 第五模块串联了2 个Inception块。\n",
    "* 第五模块的后面紧跟输出层，使用全局平均池化 层来将每个通道的高和宽变成1，最后接上一个输出个数为标签类别数的全连接层。\n",
    "\n",
    "-----\n",
    "说明：\n",
    "在原作者的论文中添加了图中所示的softmax1和softmax2两个辅助分类器，如下图所示，训练时将三个分类器的损失函数进行加权求和，以缓解梯度消失现象。这里的程序作了简化，没有加入辅助分类器。\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/fcc73767fc944464aa37c4d1112cadab90f5856a0afc49eeaa12db61c9762d0f\" width = \"600\"></center>\n",
    "<center><br>图5：GoogLeNet模型网络结构示意图</br></center>\n",
    "<br></br>\n",
    "\n",
    "GoogLeNet的具体实现如下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# GoogLeNet模型代码\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.layer_helper import LayerHelper\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, Linear\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "\n",
    "# 定义Inception块\n",
    "class Inception(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, c0,c1, c2, c3, c4, **kwargs):\n",
    "        '''\n",
    "        Inception模块的实现代码，\n",
    "        name_scope, 模块名称，数据类型为string\n",
    "        c1,  图(b)中第一条支路1x1卷积的输出通道数，数据类型是整数\n",
    "        c2，图(b)中第二条支路卷积的输出通道数，数据类型是tuple或list, \n",
    "               其中c2[0]是1x1卷积的输出通道数，c2[1]是3x3\n",
    "        c3，图(b)中第三条支路卷积的输出通道数，数据类型是tuple或list, \n",
    "               其中c3[0]是1x1卷积的输出通道数，c3[1]是3x3\n",
    "        c4,  图(b)中第一条支路1x1卷积的输出通道数，数据类型是整数\n",
    "        '''\n",
    "        super(Inception, self).__init__(name_scope)\n",
    "        # 依次创建Inception块每条支路上使用到的操作\n",
    "        self.p1_1 = Conv2D(num_channels=c0, num_filters=c1, \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p2_1 = Conv2D(num_channels=c0, num_filters=c2[0], \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p2_2 = Conv2D(num_channels=c2[0], num_filters=c2[1], \n",
    "                           filter_size=3, padding=1, act='relu')\n",
    "        self.p3_1 = Conv2D(num_channels=c0, num_filters=c3[0], \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p3_2 = Conv2D(num_channels=c3[0], num_filters=c3[1], \n",
    "                           filter_size=5, padding=2, act='relu')\n",
    "        self.p4_1 = Pool2D(pool_size=3, \n",
    "                           pool_stride=1,  pool_padding=1, \n",
    "                           pool_type='max')\n",
    "        self.p4_2 = Conv2D(num_channels=c0, num_filters=c4, \n",
    "                           filter_size=1, act='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 支路1只包含一个1x1卷积\n",
    "        p1 = self.p1_1(x)\n",
    "        # 支路2包含 1x1卷积 + 3x3卷积\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        # 支路3包含 1x1卷积 + 5x5卷积\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        # 支路4包含 最大池化和1x1卷积\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # 将每个支路的输出特征图拼接在一起作为最终的输出结果\n",
    "        return fluid.layers.concat([p1, p2, p3, p4], axis=1)  \n",
    "    \n",
    "class GoogLeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope):\n",
    "        super(GoogLeNet, self).__init__(name_scope)\n",
    "        # GoogLeNet包含五个模块，每个模块后面紧跟一个池化层\n",
    "        # 第一个模块包含1个卷积层\n",
    "        self.conv1 = Conv2D(num_channels=3, num_filters=64, filter_size=7, \n",
    "                            padding=3, act='relu')\n",
    "        # 3x3最大池化\n",
    "        self.pool1 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                            pool_padding=1, pool_type='max')\n",
    "        # 第二个模块包含2个卷积层\n",
    "        self.conv2_1 = Conv2D(num_channels=64, num_filters=64, \n",
    "                              filter_size=1, act='relu')\n",
    "        self.conv2_2 = Conv2D(num_channels=64, num_filters=192, \n",
    "                              filter_size=3, padding=1, act='relu')\n",
    "        # 3x3最大池化\n",
    "        self.pool2 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                            pool_padding=1, pool_type='max')\n",
    "        # 第三个模块包含2个Inception块\n",
    "        self.block3_1 = Inception(self.full_name(), 192, 64, (96, 128), (16, 32), 32)\n",
    "        self.block3_2 = Inception(self.full_name(), 256, 128, (128, 192), (32, 96), 64)\n",
    "        # 3x3最大池化\n",
    "        self.pool3 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                               pool_padding=1, pool_type='max')\n",
    "        # 第四个模块包含5个Inception块\n",
    "        self.block4_1 = Inception(self.full_name(), 480, 192, (96, 208), (16, 48), 64)\n",
    "        self.block4_2 = Inception(self.full_name(), 512, 160, (112, 224), (24, 64), 64)\n",
    "        self.block4_3 = Inception(self.full_name(), 512, 128, (128, 256), (24, 64), 64)\n",
    "        self.block4_4 = Inception(self.full_name(), 512, 112, (144, 288), (32, 64), 64)\n",
    "        self.block4_5 = Inception(self.full_name(), 528, 256, (160, 320), (32, 128), 128)\n",
    "        # 3x3最大池化\n",
    "        self.pool4 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                               pool_padding=1, pool_type='max')\n",
    "        # 第五个模块包含2个Inception块\n",
    "        self.block5_1 = Inception(self.full_name(), 832, 256, (160, 320), (32, 128), 128)\n",
    "        self.block5_2 = Inception(self.full_name(), 832, 384, (192, 384), (48, 128), 128)\n",
    "        # 全局池化，尺寸用的是global_pooling，pool_stride不起作用\n",
    "        self.pool5 = Pool2D(pool_stride=1, \n",
    "                               global_pooling=True, pool_type='avg')\n",
    "        self.fc = Linear(input_dim=1024, output_dim=1, act=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        x = self.pool2(self.conv2_2(self.conv2_1(x)))\n",
    "        x = self.pool3(self.block3_2(self.block3_1(x)))\n",
    "        x = self.block4_3(self.block4_2(self.block4_1(x)))\n",
    "        x = self.pool4(self.block4_5(self.block4_4(x)))\n",
    "        x = self.pool5(self.block5_2(self.block5_1(x)))\n",
    "        x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    model = GoogLeNet(\"GoogLeNet\")\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "通过运行结果可以发现，使用GoogLeNet在眼疾筛查数据集iChallenge-PM上，loss能有效的下降，经过5个epoch的训练，在验证集上的准确率可以达到95%左右。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ResNet\n",
    "\n",
    "ResNet是2015年ImageNet比赛的冠军，将识别错误率降低到了3.6%，这个结果甚至超出了正常人眼识别的精度。\n",
    "\n",
    "通过前面几个经典模型学习，我们可以发现随着深度学习的不断发展，模型的层数越来越多，网络结构也越来越复杂。那么是否加深网络结构，就一定会得到更好的效果呢？从理论上来说，假设新增加的层都是恒等映射，只要原有的层学出跟原模型一样的参数，那么深模型结构就能达到原模型结构的效果。换句话说，原模型的解只是新模型的解的子空间，在新模型解的空间里应该能找到比原模型解对应的子空间更好的结果。但是实践表明，增加网络的层数之后，训练误差往往不降反升。\n",
    "\n",
    "Kaiming He等人提出了残差网络ResNet来解决上述问题，其基本思想如 **图6**所示。\n",
    "* 图6(a)：表示增加网络的时候，将x映射成$y=F(x)$输出。\n",
    "* 图6(b)：对图6(a)作了改进，输出$y=F(x) + x$。这时不是直接学习输出特征y的表示，而是学习$y-x$。\n",
    "  - 如果想学习出原模型的表示，只需将F(x)的参数全部设置为0，则$y=x$是恒等映射。\n",
    "  - $F(x) = y - x$也叫做残差项，如果$x\\rightarrow y$的映射接近恒等映射，图6(b)中通过学习残差项也比图6(a)学习完整映射形式更加容易。\n",
    "\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/831ee61be4bb4c77b14b276fb57db941a35e8b5a340a4f74b31539bf14c00b8b\" width = \"300\"></center>\n",
    "<center><br>图6：残差块设计思想</br></center>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "图6(b)的结构是残差网络的基础，这种结构也叫做残差块（residual block）。输入x通过跨层连接，能更快的向前传播数据，或者向后传播梯度。残差块的具体设计方案如 **图**7 所示，这种设计方案也成称作瓶颈结构（BottleNeck）。\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/44fda3ea71da48c5bb7c942e3f7a824e209da50116c14d88918440e9d7f4f28a\" width = \"500\"></center>\n",
    "<center><br>图7：残差块结构示意图</br></center>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "下图表示出了ResNet-50的结构，一共包含49层卷积和1层全连接，所以被称为ResNet-50。\n",
    "\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/80d80204dda54528a1eea47073e712208b77f4b27d3b45e3901cc07c2ff9b1dc\" width = \"700\"></center>\n",
    "<center><br>图8：ResNet-50模型网络结构示意图</br></center>\n",
    "<br></br>\n",
    "\n",
    "ResNet-50的具体实现如下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# ResNet模型代码\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.layer_helper import LayerHelper\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, Linear\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "\n",
    "# ResNet中使用了BatchNorm层，在卷积层的后面加上BatchNorm以提升数值稳定性\n",
    "# 定义卷积批归一化块\n",
    "class ConvBNLayer(fluid.dygraph.Layer):\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 num_filters,\n",
    "                 filter_size,\n",
    "                 stride=1,\n",
    "                 groups=1,\n",
    "                 act=None):\n",
    "        \"\"\"\n",
    "        name_scope, 模块的名字\n",
    "        num_channels, 卷积层的输入通道数\n",
    "        num_filters, 卷积层的输出通道数\n",
    "        stride, 卷积层的步幅\n",
    "        groups, 分组卷积的组数，默认groups=1不使用分组卷积\n",
    "        act, 激活函数类型，默认act=None不使用激活函数\n",
    "        \"\"\"\n",
    "        super(ConvBNLayer, self).__init__()\n",
    "\n",
    "        # 创建卷积层\n",
    "        self._conv = Conv2D(\n",
    "            num_channels=num_channels,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=filter_size,\n",
    "            stride=stride,\n",
    "            padding=(filter_size - 1) // 2,\n",
    "            groups=groups,\n",
    "            act=None,\n",
    "            bias_attr=False)\n",
    "\n",
    "        # 创建BatchNorm层\n",
    "        self._batch_norm = BatchNorm(num_filters, act=act)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = self._conv(inputs)\n",
    "        y = self._batch_norm(y)\n",
    "        return y\n",
    "\n",
    "# 定义残差块\n",
    "# 每个残差块会对输入图片做三次卷积，然后跟输入图片进行短接\n",
    "# 如果残差块中第三次卷积输出特征图的形状与输入不一致，则对输入图片做1x1卷积，将其输出形状调整成一致\n",
    "class BottleneckBlock(fluid.dygraph.Layer):\n",
    "    def __init__(self,\n",
    "                 name_scope,\n",
    "                 num_channels,\n",
    "                 num_filters,\n",
    "                 stride,\n",
    "                 shortcut=True):\n",
    "        super(BottleneckBlock, self).__init__(name_scope)\n",
    "        # 创建第一个卷积层 1x1\n",
    "        self.conv0 = ConvBNLayer(\n",
    "            num_channels=num_channels,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=1,\n",
    "            act='relu')\n",
    "        # 创建第二个卷积层 3x3\n",
    "        self.conv1 = ConvBNLayer(\n",
    "            num_channels=num_filters,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=3,\n",
    "            stride=stride,\n",
    "            act='relu')\n",
    "        # 创建第三个卷积 1x1，但输出通道数乘以4\n",
    "        self.conv2 = ConvBNLayer(\n",
    "            num_channels=num_filters,\n",
    "            num_filters=num_filters * 4,\n",
    "            filter_size=1,\n",
    "            act=None)\n",
    "\n",
    "        # 如果conv2的输出跟此残差块的输入数据形状一致，则shortcut=True\n",
    "        # 否则shortcut = False，添加1个1x1的卷积作用在输入数据上，使其形状变成跟conv2一致\n",
    "        if not shortcut:\n",
    "            self.short = ConvBNLayer(\n",
    "                num_channels=num_channels,\n",
    "                num_filters=num_filters * 4,\n",
    "                filter_size=1,\n",
    "                stride=stride)\n",
    "\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "        self._num_channels_out = num_filters * 4\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = self.conv0(inputs)\n",
    "        conv1 = self.conv1(y)\n",
    "        conv2 = self.conv2(conv1)\n",
    "\n",
    "        # 如果shortcut=True，直接将inputs跟conv2的输出相加\n",
    "        # 否则需要对inputs进行一次卷积，将形状调整成跟conv2输出一致\n",
    "        if self.shortcut:\n",
    "            short = inputs\n",
    "        else:\n",
    "            short = self.short(inputs)\n",
    "\n",
    "        y = fluid.layers.elementwise_add(x=short, y=conv2)\n",
    "        layer_helper = LayerHelper(self.full_name(), act='relu')\n",
    "        return layer_helper.append_activation(y)\n",
    "\n",
    "# 定义ResNet模型\n",
    "class ResNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, layers=50, class_dim=1):\n",
    "        \"\"\"\n",
    "        name_scope，模块名称\n",
    "        layers, 网络层数，可以是50, 101或者152\n",
    "        class_dim，分类标签的类别数\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__(name_scope)\n",
    "        self.layers = layers\n",
    "        supported_layers = [50, 101, 152]\n",
    "        assert layers in supported_layers, \\\n",
    "            \"supported layers are {} but input layer is {}\".format(supported_layers, layers)\n",
    "\n",
    "        if layers == 50:\n",
    "            #ResNet50包含多个模块，其中第2到第5个模块分别包含3、4、6、3个残差块\n",
    "            depth = [3, 4, 6, 3]\n",
    "        elif layers == 101:\n",
    "            #ResNet101包含多个模块，其中第2到第5个模块分别包含3、4、23、3个残差块\n",
    "            depth = [3, 4, 23, 3]\n",
    "        elif layers == 152:\n",
    "            #ResNet50包含多个模块，其中第2到第5个模块分别包含3、8、36、3个残差块\n",
    "            depth = [3, 8, 36, 3]\n",
    "        \n",
    "        # 残差块中使用到的卷积的输出通道数\n",
    "        num_filters = [64, 128, 256, 512]\n",
    "\n",
    "        # ResNet的第一个模块，包含1个7x7卷积，后面跟着1个最大池化层\n",
    "        self.conv = ConvBNLayer(\n",
    "            num_channels=3,\n",
    "            num_filters=64,\n",
    "            filter_size=7,\n",
    "            stride=2,\n",
    "            act='relu')\n",
    "        self.pool2d_max = Pool2D(\n",
    "            pool_size=3,\n",
    "            pool_stride=2,\n",
    "            pool_padding=1,\n",
    "            pool_type='max')\n",
    "\n",
    "        # ResNet的第二到第五个模块c2、c3、c4、c5\n",
    "        self.bottleneck_block_list = []\n",
    "        num_channels = 64\n",
    "        for block in range(len(depth)):\n",
    "            shortcut = False\n",
    "            for i in range(depth[block]):\n",
    "                bottleneck_block = self.add_sublayer(\n",
    "                    'bb_%d_%d' % (block, i),\n",
    "                    BottleneckBlock(\n",
    "                        self.full_name(),\n",
    "                        num_channels=num_channels,\n",
    "                        num_filters=num_filters[block],\n",
    "                        stride=2 if i == 0 and block != 0 else 1, # c3、c4、c5将会在第一个残差块使用stride=2；其余所有残差块stride=1\n",
    "                        shortcut=shortcut))\n",
    "                num_channels = bottleneck_block._num_channels_out\n",
    "                self.bottleneck_block_list.append(bottleneck_block)\n",
    "                shortcut = True\n",
    "\n",
    "        # 在c5的输出特征图上使用全局池化\n",
    "        self.pool2d_avg = Pool2D(pool_size=7, pool_type='avg', global_pooling=True)\n",
    "\n",
    "        # stdv用来作为全连接层随机初始化参数的方差\n",
    "        import math\n",
    "        stdv = 1.0 / math.sqrt(2048 * 1.0)\n",
    "        \n",
    "        # 创建全连接层，输出大小为类别数目\n",
    "        self.out = Linear(input_dim=2048, output_dim=class_dim,\n",
    "                      param_attr=fluid.param_attr.ParamAttr(\n",
    "                          initializer=fluid.initializer.Uniform(-stdv, stdv)))\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        y = self.conv(inputs)\n",
    "        y = self.pool2d_max(y)\n",
    "        for bottleneck_block in self.bottleneck_block_list:\n",
    "            y = bottleneck_block(y)\n",
    "        y = self.pool2d_avg(y)\n",
    "        y = fluid.layers.reshape(y, [y.shape[0], -1])\n",
    "        y = self.out(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    model = ResNet(\"ResNet\")\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "通过运行结果可以发现，使用ResNet在眼疾筛查数据集iChallenge-PM上，loss能有效的下降，经过5个epoch的训练，在验证集上的准确率可以达到95%左右。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 小结\n",
    "\n",
    "在这一节里，给读者介绍了几种经典的图像分类模型，分别是LeNet, AlexNet, VGG, GoogLeNet和ResNet，并将它们应用到眼疾筛查数据集上。除了LeNet不适合大尺寸的图像分类问题之外，其它几个模型在此数据集上损失函数都能显著下降，在验证集上的预测精度在90%左右。如果读者有兴趣的话，可以进一步调整学习率和训练轮数等超参数，观察是否能够得到更高的精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 参考文献\n",
    "\n",
    "[1] Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learn- ing applied to document recognition. Proc. of the IEEE, 86(11):2278–2324, 1998 \n",
    "\n",
    "[2] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems, pages 1097–1105, 2012. \n",
    "\n",
    "[3] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014b. \n",
    "\n",
    "[4]Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolu- tions. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1–9, 2015. \n",
    "\n",
    "[5] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im- age recognition. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770–778, 2016a. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 作业\n",
    "\n",
    "1、如果将LeNet中中间层的激活函数Sigmoid换成ReLU，在眼底筛查数据集上将会得到什么样的结果？Loss是否能收敛，ReLU和Sigmoid之间的区别是引起结果不同的原因吗？请发表你的观点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
